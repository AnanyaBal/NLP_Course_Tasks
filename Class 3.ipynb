{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a paragraph: Swimming, drowsiness, business, disappoint, trustworthy, incorporate, malicious, delicious, classify, leafy, article, poodle, sacrificial, sacrifice\n",
      "['Swimming', 'drowsiness', 'business', 'disappoint', 'trustworthy', 'incorporate', 'malicious', 'delicious', 'classify', 'leafy', 'article', 'poodle', 'sacrificial', 'sacrifice']\n",
      "['swim', 'drowsi', 'busi', 'disappoint', 'trustworthi', 'incorpor', 'malici', 'delici', 'classifi', 'leafi', 'articl', 'poodl', 'sacrifici', 'sacrific']\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Enter a paragraph: \")\n",
    "\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "my_str = text\n",
    "rtext = \"\"\n",
    "for char in my_str:\n",
    "   if char not in punctuations:\n",
    "       rtext = rtext + char\n",
    "        \n",
    "paragraph = nltk.sent_tokenize(rtext) \n",
    "# looping over each sentence to tokenize it separately\n",
    "for sentence in paragraph:\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    #print(tokenized_text)\n",
    "    \n",
    "print(tokenized_text)\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmerporter = PorterStemmer()\n",
    "stemmed=[stemmerporter.stem(i) for i in tokenized_text]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['swim', 'drowsy', 'busy', 'disappoint', 'trustworthy', 'incorp', 'malicy', 'delicy', 'class', 'leafy', 'artic', 'poodl', 'sacr', 'sacr']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "stemmerlancaster = LancasterStemmer()\n",
    "lstemmed=[stemmerlancaster.stem(i) for i in tokenized_text]\n",
    "print(lstemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['swim', 'drowsi', 'busi', 'disappoint', 'trustworthi', 'incorpor', 'malici', 'delici', 'classifi', 'leafi', 'articl', 'poodl', 'sacrifici', 'sacrific']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmersnowball = SnowballStemmer(\"english\")\n",
    "sstemmed=[stemmersnowball.stem(i) for i in tokenized_text]\n",
    "print(sstemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Swimming', 'drowsiness', 'business', 'disappoint', 'trustworthy', 'incorporate', 'malicious', 'delicious', 'classify', 'leafy', 'article', 'poodle', 'sacrificial', 'sacrifice']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lword1=[wordnet_lemmatizer.lemmatize(i) for i in tokenized_text]\n",
    "print(lword1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "restemmer=RegexpStemmer('ing')\n",
    "restemmer.stem('working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
