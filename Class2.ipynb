{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n",
      "Number of entries:  133737\n",
      "CMU word list:  ('abdication', ['AE2', 'B', 'D', 'IH0', 'K', 'EY1', 'SH', 'AH0', 'N'])\n",
      "CMU word list:  ('abdnor', ['AE1', 'B', 'D', 'N', 'ER0'])\n",
      "CMU word list:  ('abdo', ['AE1', 'B', 'D', 'OW0'])\n",
      "CMU word list:  ('abdollah', ['AE2', 'B', 'D', 'AA1', 'L', 'AH0'])\n",
      "CMU word list:  ('abdomen', ['AE0', 'B', 'D', 'OW1', 'M', 'AH0', 'N'])\n",
      "CMU word list:  ('abdomen', ['AE1', 'B', 'D', 'AH0', 'M', 'AH0', 'N'])\n",
      "CMU word list:  ('abdominal', ['AE0', 'B', 'D', 'AA1', 'M', 'AH0', 'N', 'AH0', 'L'])\n",
      "CMU word list:  ('abdominal', ['AH0', 'B', 'D', 'AA1', 'M', 'AH0', 'N', 'AH0', 'L'])\n",
      "CMU word list:  ('abduct', ['AE0', 'B', 'D', 'AH1', 'K', 'T'])\n",
      "CMU word list:  ('abducted', ['AE0', 'B', 'D', 'AH1', 'K', 'T', 'IH0', 'D'])\n",
      "CMU word list:  ('abducted', ['AH0', 'B', 'D', 'AH1', 'K', 'T', 'IH0', 'D'])\n",
      "CMU word list:  ('abductee', ['AE0', 'B', 'D', 'AH2', 'K', 'T', 'IY1'])\n",
      "CMU word list:  ('abductees', ['AE0', 'B', 'D', 'AH2', 'K', 'T', 'IY1', 'Z'])\n",
      "CMU word list:  ('abducting', ['AE0', 'B', 'D', 'AH1', 'K', 'T', 'IH0', 'NG'])\n",
      "CMU word list:  ('abducting', ['AH0', 'B', 'D', 'AH1', 'K', 'T', 'IH0', 'NG'])\n",
      "CMU word list:  ('abduction', ['AE0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N'])\n",
      "CMU word list:  ('abduction', ['AH0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N'])\n",
      "CMU word list:  ('abductions', ['AE0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N', 'Z'])\n",
      "CMU word list:  ('abductions', ['AH0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N', 'Z'])\n",
      "CMU word list:  ('abductor', ['AE0', 'B', 'D', 'AH1', 'K', 'T', 'ER0'])\n",
      "CMU word list:  ('abductor', ['AH0', 'B', 'D', 'AH1', 'K', 'T', 'ER0'])\n",
      "CMU word list:  ('abductors', ['AE0', 'B', 'D', 'AH1', 'K', 'T', 'ER0', 'Z'])\n",
      "CMU word list:  ('abductors', ['AH0', 'B', 'D', 'AH1', 'K', 'T', 'ER0', 'Z'])\n",
      "CMU word list:  ('abducts', ['AE0', 'B', 'D', 'AH1', 'K', 'T', 'S'])\n",
      "CMU word list:  ('abdul', ['AE0', 'B', 'D', 'UW1', 'L'])\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#lexicon1\n",
    "#CMU wordlist for phenomes for phonetic pronounciations\n",
    "nltk.download('cmudict')\n",
    "\n",
    "entries = nltk.corpus.cmudict.entries()\n",
    "print(\"Number of entries: \", len(entries))\n",
    "for entry in entries[100:125]:\n",
    "    print(\"CMU word list: \", entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "['universe', 'existence', 'creation', 'world', 'cosmos', 'macrocosm']\n",
      "['world', 'domain']\n",
      "['world', 'reality']\n",
      "['Earth', 'earth', 'world', 'globe']\n",
      "['populace', 'public', 'world']\n",
      "['world']\n",
      "['worldly_concern', 'earthly_concern', 'world', 'earth']\n",
      "['world', 'human_race', 'humanity', 'humankind', 'human_beings', 'humans', 'mankind', 'man']\n",
      "['global', 'planetary', 'world', 'worldwide', 'world-wide']\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#Lexicon2\n",
    "#synonyms from synset\n",
    "from nltk.corpus import wordnet as wn\n",
    "id = wn.synsets('world') #you get an id for subsets\n",
    "print(len(id))\n",
    "for i in range (0,len(id)):\n",
    "        print(id[i].lemma_names()) #head words/lemmas in the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[('The', 'DT'), ('Devon', 'NNP'), ('County', 'NNP'), ('War', 'NNP'), ('Memorial', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('First', 'JJ'), ('World', 'NNP'), ('War', 'NNP'), ('memorial', 'NN'), ('on', 'IN'), ('Cathedral', 'NNP'), ('Green', 'NNP'), ('in', 'IN'), ('Exeter', 'NNP'), (',', ','), ('the', 'DT'), ('county', 'NN'), ('town', 'NN'), ('of', 'IN'), ('Devon', 'NNP'), (',', ','), ('in', 'IN'), ('the', 'DT'), ('south', 'JJ'), ('west', 'NN'), ('of', 'IN'), ('England', 'NNP'), ('.', '.')]\n",
      "[('It', 'PRP'), ('is', 'VBZ'), ('one', 'CD'), ('of', 'IN'), ('fifteen', 'JJ'), ('War', 'NNP'), ('Crosses', 'NNP'), ('designed', 'VBN'), ('by', 'IN'), ('Sir', 'NNP'), ('Edwin', 'NNP'), ('Lutyens', 'NNP'), ('to', 'TO'), ('a', 'DT'), ('similar', 'JJ'), ('specification', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('Devon', 'NNP'), ('County', 'NNP'), ('War', 'NNP'), ('Memorial', 'NNP'), ('Committee', 'NNP'), ('commissioned', 'VBD'), ('Lutyens', 'NNP'), ('to', 'TO'), ('design', 'VB'), ('a', 'DT'), ('War', 'NNP'), ('Cross', 'NNP'), ('and', 'CC'), ('chose', 'VBD'), ('to', 'TO'), ('site', 'NN'), ('it', 'PRP'), ('at', 'IN'), ('Exeter', 'NNP'), ('Cathedral', 'NNP'), ('.', '.')]\n",
      "[('Hewn', 'NNP'), ('from', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('block', 'NN'), ('of', 'IN'), ('granite', 'NN'), ('quarried', 'VBN'), ('from', 'IN'), ('Haytor', 'NNP'), ('on', 'IN'), ('Dartmoor', 'NNP'), (',', ','), ('it', 'PRP'), ('stands', 'VBZ'), ('just', 'RB'), ('to', 'TO'), ('the', 'DT'), ('west', 'NN'), ('of', 'IN'), ('the', 'DT'), ('cathedral', 'JJ'), (',', ','), ('in', 'IN'), ('alignment', 'NN'), ('with', 'IN'), ('the', 'DT'), ('altar', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('cross', 'NN'), ('stands', 'VBZ'), ('on', 'IN'), ('a', 'DT'), ('granite', 'JJ'), ('plinth', 'NN'), (',', ','), ('which', 'WDT'), ('itself', 'PRP'), ('sits', 'VBZ'), ('on', 'IN'), ('three', 'CD'), ('steps', 'NNS'), ('.', '.')]\n",
      "[('After', 'IN'), ('archaeological', 'JJ'), ('excavations', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('1970s', 'CD'), (',', ','), ('the', 'DT'), ('area', 'NN'), ('was', 'VBD'), ('remodelled', 'VBN'), ('to', 'TO'), ('create', 'VB'), ('a', 'DT'), ('processional', 'JJ'), ('way', 'NN'), ('between', 'IN'), ('the', 'DT'), ('memorial', 'NN'), ('and', 'CC'), ('the', 'DT'), ('cathedral', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('memorial', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('grade', 'JJ'), ('II*', 'NNP'), ('listed', 'VBD'), ('building', 'NN'), ('and', 'CC'), ('is', 'VBZ'), ('included', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('national', 'JJ'), ('collection', 'NN'), ('of', 'IN'), ('Lutyens', 'NNP'), (\"'\", 'POS'), ('war', 'NN'), ('memorials', 'NNS'), ('.', '.')]\n",
      "[('It', 'PRP'), ('commemorates', 'VBZ'), ('the', 'DT'), ('war', 'NN'), ('dead', 'NN'), ('of', 'IN'), ('the', 'DT'), ('county', 'NN'), ('of', 'IN'), ('Devon', 'NNP'), (';', ':'), ('the', 'DT'), ('Exeter', 'NNP'), ('City', 'NNP'), ('War', 'NNP'), ('Memorial', 'NNP'), ('in', 'IN'), ('Northernhay', 'NNP'), ('Gardens', 'NNP'), ('honours', 'VBP'), ('those', 'DT'), ('from', 'IN'), ('the', 'DT'), ('city', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#NLTK pipeline\n",
    "texts = [\"\"\"The Devon County War Memorial is a First World War memorial on Cathedral Green in Exeter, the county town of Devon, in the south west of England. \n",
    "It is one of fifteen War Crosses designed by Sir Edwin Lutyens to a similar specification. \n",
    "The Devon County War Memorial Committee commissioned Lutyens to design a War Cross and chose to site it at Exeter Cathedral.\n",
    "Hewn from a single block of granite quarried from Haytor on Dartmoor, it stands just to the west of the cathedral, in alignment with the altar. \n",
    "The cross stands on a granite plinth, which itself sits on three steps. After archaeological excavations in the 1970s, the area was remodelled to create a processional way between the memorial and the cathedral. \n",
    "The memorial is a grade II* listed building and is included in a national collection of Lutyens' war memorials. \n",
    "It commemorates the war dead of the county of Devon; the Exeter City War Memorial in Northernhay Gardens honours those from the city.\"\"\"] #paste text after the three quotes, organize into lines\n",
    "\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "  \n",
    "for text in texts:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged_words = nltk.pos_tag(words)\n",
    "        print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweepy tokeniser\n",
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(\"---\", \"---\")\n",
    "auth.set_access_token(\"---\", \"---\")\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization:  ['this', 'party', 'is', 'so', 'fun', 'lol', '#saturday']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "public_tweets=\"this party is so fun lol #saturday\"\n",
    "\n",
    "\n",
    "word = tknzr.tokenize(public_tweets)\n",
    "print(\"Tokenization: \", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
